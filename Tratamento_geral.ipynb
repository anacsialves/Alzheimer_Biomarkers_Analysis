{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b419872",
   "metadata": {},
   "source": [
    "Tratamento geral dos dados\n",
    "=========================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4b3da0",
   "metadata": {},
   "source": [
    "Esse `notebook` tem por objetivo realizar o primeiro contato com os dados que serão, posteriormente, utilizados para induzir `modelos` `preditivos`. De forma geral, o que será realizado é a remoção de `dados` `faltantes`; a remoção de linhas (exemplos) `redundantes`, ou seja, que não agregam `informação` ao problema e podem comprometre a métrica de desempenho do modelo; a conversão de dados `categóricos` (apenas uma coluna se encaixa nesse exemplo) em `numéricos`; e a separção em `features` e `targets`. Ao final, será gerado um conjunto de `Dataframes` que será utilizado para induzir os `modelos` `preditivos`. Esse dataframe será do tipo _ComPode começarma-Separated Values_ (CSV)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c6cfff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da25a9b8",
   "metadata": {},
   "source": [
    "## Importando o `Dataframe`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c222d9c",
   "metadata": {},
   "source": [
    "Podemos carregar o `Dataframe`, obtido por meio da referência [1], no programa por meio da `biblioteca` `pandas`. O arquivo é um CSV. Após ler o arquivo, podemos mostrar parte do `Dataframe` para criar a referência tabular dos dados.\n",
    "\n",
    "Junto à importação, podemos retirar exemplos que tenham, por ventura, dados faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0b2859d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACE_CD143_Angiotensin_Converti</th>\n",
       "      <th>ACTH_Adrenocorticotropic_Hormon</th>\n",
       "      <th>AXL</th>\n",
       "      <th>Adiponectin</th>\n",
       "      <th>Alpha_1_Antichymotrypsin</th>\n",
       "      <th>Alpha_1_Antitrypsin</th>\n",
       "      <th>Alpha_1_Microglobulin</th>\n",
       "      <th>Alpha_2_Macroglobulin</th>\n",
       "      <th>Angiopoietin_2_ANG_2</th>\n",
       "      <th>Angiotensinogen</th>\n",
       "      <th>...</th>\n",
       "      <th>VEGF</th>\n",
       "      <th>Vitronectin</th>\n",
       "      <th>von_Willebrand_Factor</th>\n",
       "      <th>age</th>\n",
       "      <th>tau</th>\n",
       "      <th>p_tau</th>\n",
       "      <th>Ab_42</th>\n",
       "      <th>male</th>\n",
       "      <th>Genotype</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rownames</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.003100</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>1.098387</td>\n",
       "      <td>-5.360193</td>\n",
       "      <td>1.740466</td>\n",
       "      <td>-12.631361</td>\n",
       "      <td>-2.577022</td>\n",
       "      <td>-72.650290</td>\n",
       "      <td>1.064711</td>\n",
       "      <td>2.510547</td>\n",
       "      <td>...</td>\n",
       "      <td>22.034564</td>\n",
       "      <td>-0.040822</td>\n",
       "      <td>-3.146555</td>\n",
       "      <td>0.987624</td>\n",
       "      <td>6.297754</td>\n",
       "      <td>4.348108</td>\n",
       "      <td>12.019678</td>\n",
       "      <td>0</td>\n",
       "      <td>E3E3</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.561856</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>0.683282</td>\n",
       "      <td>-5.020686</td>\n",
       "      <td>1.458615</td>\n",
       "      <td>-11.909882</td>\n",
       "      <td>-3.244194</td>\n",
       "      <td>-154.612278</td>\n",
       "      <td>0.741937</td>\n",
       "      <td>2.457283</td>\n",
       "      <td>...</td>\n",
       "      <td>18.601843</td>\n",
       "      <td>-0.385662</td>\n",
       "      <td>-3.863233</td>\n",
       "      <td>0.986150</td>\n",
       "      <td>6.659294</td>\n",
       "      <td>4.859967</td>\n",
       "      <td>11.015759</td>\n",
       "      <td>0</td>\n",
       "      <td>E3E4</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.520660</td>\n",
       "      <td>-1.714798</td>\n",
       "      <td>-0.145276</td>\n",
       "      <td>-5.809143</td>\n",
       "      <td>1.193922</td>\n",
       "      <td>-13.642963</td>\n",
       "      <td>-2.882404</td>\n",
       "      <td>-136.529178</td>\n",
       "      <td>0.832909</td>\n",
       "      <td>1.976365</td>\n",
       "      <td>...</td>\n",
       "      <td>17.476191</td>\n",
       "      <td>-0.223144</td>\n",
       "      <td>-3.540459</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>6.270988</td>\n",
       "      <td>4.400247</td>\n",
       "      <td>12.302271</td>\n",
       "      <td>1</td>\n",
       "      <td>E3E4</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.680826</td>\n",
       "      <td>-1.609438</td>\n",
       "      <td>0.683282</td>\n",
       "      <td>-5.115996</td>\n",
       "      <td>1.280934</td>\n",
       "      <td>-15.523564</td>\n",
       "      <td>-3.170086</td>\n",
       "      <td>-98.361752</td>\n",
       "      <td>0.916291</td>\n",
       "      <td>2.376085</td>\n",
       "      <td>...</td>\n",
       "      <td>17.545595</td>\n",
       "      <td>-0.653926</td>\n",
       "      <td>-3.863233</td>\n",
       "      <td>0.986702</td>\n",
       "      <td>6.152733</td>\n",
       "      <td>4.494886</td>\n",
       "      <td>12.398138</td>\n",
       "      <td>0</td>\n",
       "      <td>E3E4</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.400931</td>\n",
       "      <td>-0.967584</td>\n",
       "      <td>0.190890</td>\n",
       "      <td>-4.779524</td>\n",
       "      <td>2.128232</td>\n",
       "      <td>-11.133063</td>\n",
       "      <td>-2.343407</td>\n",
       "      <td>-144.944601</td>\n",
       "      <td>0.955511</td>\n",
       "      <td>2.862219</td>\n",
       "      <td>...</td>\n",
       "      <td>20.778602</td>\n",
       "      <td>0.166216</td>\n",
       "      <td>-3.816713</td>\n",
       "      <td>0.987163</td>\n",
       "      <td>6.623707</td>\n",
       "      <td>4.524589</td>\n",
       "      <td>11.024109</td>\n",
       "      <td>0</td>\n",
       "      <td>E3E3</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>1.719055</td>\n",
       "      <td>-1.660731</td>\n",
       "      <td>0.828427</td>\n",
       "      <td>-5.449140</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>-16.321511</td>\n",
       "      <td>-3.324236</td>\n",
       "      <td>-160.010404</td>\n",
       "      <td>0.955511</td>\n",
       "      <td>1.908566</td>\n",
       "      <td>...</td>\n",
       "      <td>17.517898</td>\n",
       "      <td>-0.446287</td>\n",
       "      <td>-3.729701</td>\n",
       "      <td>0.983687</td>\n",
       "      <td>6.132899</td>\n",
       "      <td>4.430662</td>\n",
       "      <td>11.913409</td>\n",
       "      <td>0</td>\n",
       "      <td>E3E3</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>1.391905</td>\n",
       "      <td>-1.514128</td>\n",
       "      <td>-0.145276</td>\n",
       "      <td>-4.906275</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>-11.838035</td>\n",
       "      <td>-2.120264</td>\n",
       "      <td>-154.612278</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>1.789161</td>\n",
       "      <td>...</td>\n",
       "      <td>15.618049</td>\n",
       "      <td>0.205439</td>\n",
       "      <td>-4.509860</td>\n",
       "      <td>0.984351</td>\n",
       "      <td>4.805741</td>\n",
       "      <td>3.357803</td>\n",
       "      <td>12.878940</td>\n",
       "      <td>1</td>\n",
       "      <td>E3E4</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>1.001198</td>\n",
       "      <td>-1.347074</td>\n",
       "      <td>-0.010025</td>\n",
       "      <td>-4.509860</td>\n",
       "      <td>1.193922</td>\n",
       "      <td>-14.406260</td>\n",
       "      <td>-3.170086</td>\n",
       "      <td>-179.087488</td>\n",
       "      <td>-0.248461</td>\n",
       "      <td>2.596327</td>\n",
       "      <td>...</td>\n",
       "      <td>14.543388</td>\n",
       "      <td>-0.478036</td>\n",
       "      <td>-4.509860</td>\n",
       "      <td>0.986877</td>\n",
       "      <td>5.551835</td>\n",
       "      <td>3.768614</td>\n",
       "      <td>9.508593</td>\n",
       "      <td>0</td>\n",
       "      <td>E3E3</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>0.946207</td>\n",
       "      <td>-1.771957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.521461</td>\n",
       "      <td>1.704748</td>\n",
       "      <td>-12.543721</td>\n",
       "      <td>-3.036554</td>\n",
       "      <td>-132.715082</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>2.289800</td>\n",
       "      <td>...</td>\n",
       "      <td>16.363273</td>\n",
       "      <td>0.182322</td>\n",
       "      <td>-4.342806</td>\n",
       "      <td>0.984227</td>\n",
       "      <td>4.595120</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>13.072866</td>\n",
       "      <td>1</td>\n",
       "      <td>E3E3</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>2.428972</td>\n",
       "      <td>-1.469676</td>\n",
       "      <td>1.405877</td>\n",
       "      <td>-5.051457</td>\n",
       "      <td>1.280934</td>\n",
       "      <td>-12.907477</td>\n",
       "      <td>-2.995732</td>\n",
       "      <td>-194.946840</td>\n",
       "      <td>1.252763</td>\n",
       "      <td>2.498534</td>\n",
       "      <td>...</td>\n",
       "      <td>22.346078</td>\n",
       "      <td>-0.328504</td>\n",
       "      <td>-4.074542</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>5.603815</td>\n",
       "      <td>4.727919</td>\n",
       "      <td>14.170699</td>\n",
       "      <td>0</td>\n",
       "      <td>E3E4</td>\n",
       "      <td>Control</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ACE_CD143_Angiotensin_Converti  ACTH_Adrenocorticotropic_Hormon  \\\n",
       "rownames                                                                    \n",
       "1                               2.003100                        -1.386294   \n",
       "2                               1.561856                        -1.386294   \n",
       "3                               1.520660                        -1.714798   \n",
       "4                               1.680826                        -1.609438   \n",
       "5                               2.400931                        -0.967584   \n",
       "...                                  ...                              ...   \n",
       "329                             1.719055                        -1.660731   \n",
       "330                             1.391905                        -1.514128   \n",
       "331                             1.001198                        -1.347074   \n",
       "332                             0.946207                        -1.771957   \n",
       "333                             2.428972                        -1.469676   \n",
       "\n",
       "               AXL  Adiponectin  Alpha_1_Antichymotrypsin  \\\n",
       "rownames                                                    \n",
       "1         1.098387    -5.360193                  1.740466   \n",
       "2         0.683282    -5.020686                  1.458615   \n",
       "3        -0.145276    -5.809143                  1.193922   \n",
       "4         0.683282    -5.115996                  1.280934   \n",
       "5         0.190890    -4.779524                  2.128232   \n",
       "...            ...          ...                       ...   \n",
       "329       0.828427    -5.449140                  1.098612   \n",
       "330      -0.145276    -4.906275                  1.609438   \n",
       "331      -0.010025    -4.509860                  1.193922   \n",
       "332       0.000000    -5.521461                  1.704748   \n",
       "333       1.405877    -5.051457                  1.280934   \n",
       "\n",
       "          Alpha_1_Antitrypsin  Alpha_1_Microglobulin  Alpha_2_Macroglobulin  \\\n",
       "rownames                                                                      \n",
       "1                  -12.631361              -2.577022             -72.650290   \n",
       "2                  -11.909882              -3.244194            -154.612278   \n",
       "3                  -13.642963              -2.882404            -136.529178   \n",
       "4                  -15.523564              -3.170086             -98.361752   \n",
       "5                  -11.133063              -2.343407            -144.944601   \n",
       "...                       ...                    ...                    ...   \n",
       "329                -16.321511              -3.324236            -160.010404   \n",
       "330                -11.838035              -2.120264            -154.612278   \n",
       "331                -14.406260              -3.170086            -179.087488   \n",
       "332                -12.543721              -3.036554            -132.715082   \n",
       "333                -12.907477              -2.995732            -194.946840   \n",
       "\n",
       "          Angiopoietin_2_ANG_2  Angiotensinogen  ...       VEGF  Vitronectin  \\\n",
       "rownames                                         ...                           \n",
       "1                     1.064711         2.510547  ...  22.034564    -0.040822   \n",
       "2                     0.741937         2.457283  ...  18.601843    -0.385662   \n",
       "3                     0.832909         1.976365  ...  17.476191    -0.223144   \n",
       "4                     0.916291         2.376085  ...  17.545595    -0.653926   \n",
       "5                     0.955511         2.862219  ...  20.778602     0.166216   \n",
       "...                        ...              ...  ...        ...          ...   \n",
       "329                   0.955511         1.908566  ...  17.517898    -0.446287   \n",
       "330                   0.405465         1.789161  ...  15.618049     0.205439   \n",
       "331                  -0.248461         2.596327  ...  14.543388    -0.478036   \n",
       "332                   0.405465         2.289800  ...  16.363273     0.182322   \n",
       "333                   1.252763         2.498534  ...  22.346078    -0.328504   \n",
       "\n",
       "          von_Willebrand_Factor       age       tau     p_tau      Ab_42  \\\n",
       "rownames                                                                   \n",
       "1                     -3.146555  0.987624  6.297754  4.348108  12.019678   \n",
       "2                     -3.863233  0.986150  6.659294  4.859967  11.015759   \n",
       "3                     -3.540459  0.986667  6.270988  4.400247  12.302271   \n",
       "4                     -3.863233  0.986702  6.152733  4.494886  12.398138   \n",
       "5                     -3.816713  0.987163  6.623707  4.524589  11.024109   \n",
       "...                         ...       ...       ...       ...        ...   \n",
       "329                   -3.729701  0.983687  6.132899  4.430662  11.913409   \n",
       "330                   -4.509860  0.984351  4.805741  3.357803  12.878940   \n",
       "331                   -4.509860  0.986877  5.551835  3.768614   9.508593   \n",
       "332                   -4.342806  0.984227  4.595120  3.218876  13.072866   \n",
       "333                   -4.074542  0.984848  5.603815  4.727919  14.170699   \n",
       "\n",
       "          male  Genotype    Class  \n",
       "rownames                           \n",
       "1            0      E3E3  Control  \n",
       "2            0      E3E4  Control  \n",
       "3            1      E3E4  Control  \n",
       "4            0      E3E4  Control  \n",
       "5            0      E3E3  Control  \n",
       "...        ...       ...      ...  \n",
       "329          0      E3E3  Control  \n",
       "330          1      E3E4  Control  \n",
       "331          0      E3E3  Control  \n",
       "332          1      E3E3  Control  \n",
       "333          0      E3E4  Control  \n",
       "\n",
       "[333 rows x 131 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Os índices já são definidos no próprio arquivo com a coluna \"rownames\"\n",
    "df = pd.read_csv('Dataset_Alzheimers.csv', index_col='rownames', sep=',' )\n",
    "df.dropna(axis=0, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4082e408",
   "metadata": {},
   "source": [
    "## Definindo as features e targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c732f93",
   "metadata": {},
   "source": [
    "Para continuar, devemos diferenciar as `colunas` que fornecem `informação` acerca do caso e as que definem o que queremos descobrir sobre o indivíduo. Nesse caso, o objetivo é prever se há, ou não, predisposição à alzheimer, baseando a análise em todos os outros dados fronecidos. Assim, nosso `target` será `categórico` (_Control ou Impaired_) e nossas `features` devem ser `numéricas` para o funcionamento dos `algoritmos`.\n",
    "\n",
    "OBS: As `variáveis` `features` e `targets` são `listas` com _nomes_ de `colunas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54a15f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As features são todas as colunas com exceção da coluna \"Class\"\n",
    "features = df.columns.tolist()\n",
    "features.remove('Class')\n",
    "\n",
    "# O target é a coluna \"Class\"\n",
    "target = ['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb5bb36",
   "metadata": {},
   "source": [
    "## Eliminando dados redundantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa32e758",
   "metadata": {},
   "source": [
    "Dados, ou seja, exemplos, que sejam iguais ou muito próximos podem caracterizar `vazamento` de `dados`. Isso significa que quando o `desempenho` do modelo for medido, o valor pode estar sendo superestimando, em rasão de ele ter sido treinado com dados \"já conhecidos\". Uma estratégia para evitar isso é agrupar esses exemplos e colapssá-los em um único valor, sua `moda`. Primeiramente, pode-se `arredondar` os valores para evitar superestimar a precisão do equipamento, depois executa-se o procedimento de `colapso`.\n",
    "\n",
    "OBS: A `moda` é usada nesse caso pois o `target` que será `previsto` é uma _classe_, não um número."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "216e3a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joao25006\\AppData\\Local\\Temp\\ipykernel_20056\\2210588839.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_tratado = grupo.reset_index()\n",
      "C:\\Users\\joao25006\\AppData\\Local\\Temp\\ipykernel_20056\\2210588839.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_tratado = grupo.reset_index()\n",
      "C:\\Users\\joao25006\\AppData\\Local\\Temp\\ipykernel_20056\\2210588839.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_tratado = grupo.reset_index()\n",
      "C:\\Users\\joao25006\\AppData\\Local\\Temp\\ipykernel_20056\\2210588839.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_tratado = grupo.reset_index()\n",
      "C:\\Users\\joao25006\\AppData\\Local\\Temp\\ipykernel_20056\\2210588839.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_tratado = grupo.reset_index()\n",
      "C:\\Users\\joao25006\\AppData\\Local\\Temp\\ipykernel_20056\\2210588839.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_tratado = grupo.reset_index()\n",
      "C:\\Users\\joao25006\\AppData\\Local\\Temp\\ipykernel_20056\\2210588839.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_tratado = grupo.reset_index()\n",
      "C:\\Users\\joao25006\\AppData\\Local\\Temp\\ipykernel_20056\\2210588839.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_tratado = grupo.reset_index()\n",
      "C:\\Users\\joao25006\\AppData\\Local\\Temp\\ipykernel_20056\\2210588839.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_tratado = grupo.reset_index()\n",
      "C:\\Users\\joao25006\\AppData\\Local\\Temp\\ipykernel_20056\\2210588839.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_tratado = grupo.reset_index()\n",
      "C:\\Users\\joao25006\\AppData\\Local\\Temp\\ipykernel_20056\\2210588839.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_tratado = grupo.reset_index()\n",
      "C:\\Users\\joao25006\\AppData\\Local\\Temp\\ipykernel_20056\\2210588839.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_tratado = grupo.reset_index()\n",
      "C:\\Users\\joao25006\\AppData\\Local\\Temp\\ipykernel_20056\\2210588839.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_tratado = grupo.reset_index()\n",
      "C:\\Users\\joao25006\\AppData\\Local\\Temp\\ipykernel_20056\\2210588839.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_tratado = grupo.reset_index()\n",
      "C:\\Users\\joao25006\\AppData\\Local\\Temp\\ipykernel_20056\\2210588839.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_tratado = grupo.reset_index()\n",
      "C:\\Users\\joao25006\\AppData\\Local\\Temp\\ipykernel_20056\\2210588839.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_tratado = grupo.reset_index()\n",
      "C:\\Users\\joao25006\\AppData\\Local\\Temp\\ipykernel_20056\\2210588839.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_tratado = grupo.reset_index()\n",
      "C:\\Users\\joao25006\\AppData\\Local\\Temp\\ipykernel_20056\\2210588839.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_tratado = grupo.reset_index()\n",
      "C:\\Users\\joao25006\\AppData\\Local\\Temp\\ipykernel_20056\\2210588839.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_tratado = grupo.reset_index()\n",
      "C:\\Users\\joao25006\\AppData\\Local\\Temp\\ipykernel_20056\\2210588839.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_tratado = grupo.reset_index()\n",
      "C:\\Users\\joao25006\\AppData\\Local\\Temp\\ipykernel_20056\\2210588839.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_tratado = grupo.reset_index()\n",
      "C:\\Users\\joao25006\\AppData\\Local\\Temp\\ipykernel_20056\\2210588839.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_tratado = grupo.reset_index()\n",
      "C:\\Users\\joao25006\\AppData\\Local\\Temp\\ipykernel_20056\\2210588839.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_tratado = grupo.reset_index()\n",
      "C:\\Users\\joao25006\\AppData\\Local\\Temp\\ipykernel_20056\\2210588839.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_tratado = grupo.reset_index()\n",
      "C:\\Users\\joao25006\\AppData\\Local\\Temp\\ipykernel_20056\\2210588839.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_tratado = grupo.reset_index()\n",
      "C:\\Users\\joao25006\\AppData\\Local\\Temp\\ipykernel_20056\\2210588839.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_tratado = grupo.reset_index()\n",
      "C:\\Users\\joao25006\\AppData\\Local\\Temp\\ipykernel_20056\\2210588839.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_tratado = grupo.reset_index()\n",
      "C:\\Users\\joao25006\\AppData\\Local\\Temp\\ipykernel_20056\\2210588839.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_tratado = grupo.reset_index()\n",
      "C:\\Users\\joao25006\\AppData\\Local\\Temp\\ipykernel_20056\\2210588839.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_tratado = grupo.reset_index()\n",
      "C:\\Users\\joao25006\\AppData\\Local\\Temp\\ipykernel_20056\\2210588839.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_tratado = grupo.reset_index()\n",
      "C:\\Users\\joao25006\\AppData\\Local\\Temp\\ipykernel_20056\\2210588839.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_tratado = grupo.reset_index()\n"
     ]
    }
   ],
   "source": [
    "casas_arredondamento = 5 # Define quantas casas decimais o número vai ter\n",
    "\n",
    "df_round = df.round(casas_arredondamento)\n",
    "\n",
    "# Agrupa os targets por meio das features. Caso existam dois exemplos iguais, atribui àquela combinação de valores, a moda dos targets agrupados\n",
    "grupo = df_round.groupby(features, sort=False)[target].agg(pd.Series.mode)\n",
    "df_tratado = grupo.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1483edcf",
   "metadata": {},
   "source": [
    "## Conversão simbólico-numérica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73d8137",
   "metadata": {},
   "source": [
    "Como é possível perceber, há, entre as `features`, um dado que é categórico binário. Para torná-lo numérico é possível utilizar a função `.get_dummies` para realizar a conversão do tipo `OneHot`. A conversão só precisa ser realizada nas features então, na `célula` abaixo o `Dataframe` de `features` é separado. Por facilidade para os próximo passos, o Dataframe de teste também é separado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6551bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = df_tratado[features]\n",
    "df_target = df_tratado[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a13dfc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = pd.get_dummies(df_features, dtype=int, drop_first=True)\n",
    "features = df_features.columns.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79350f16",
   "metadata": {},
   "source": [
    "### Organizando"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e41b8af",
   "metadata": {},
   "source": [
    "Para definir bem o que já foi feito até agora, a `célula` abaixo reúne as `variáveis` _importantes_ (que serão utilizadas nos próximos passos) criadas até o momento. Uma `lista` com as _features_; um `Dataframe` com as _features_; uma `lista` ocm o _target_; um `Dataframe` com o _target_\n",
    "\n",
    "OBS: O ponto e vírugula ao final serve para que o `Jupyter` não exiba o `Dataframe` e gera poluição visual no `notebook`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed7c9164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "features\n",
    "df_features\n",
    "\n",
    "# Target\n",
    "target\n",
    "df_target;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155baef2",
   "metadata": {},
   "source": [
    "## Split em treino e teste (`holdout`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17dfa42c",
   "metadata": {},
   "source": [
    "É de grande importância, após treinar um modelo preditivo, testar a \"eficiência\" desse moodelo em prever o que foi pedido. Uma estratégia para avaliar o desempenho de um modelo é, após seu treinamento, realizar uma \"prova\" com dados que o _modelo nunca tenha tido contato de nenhuma forma_. Isso permite avaliar a _taxa de acerto_ do modelo. Para `regressores`, essa medida está, muitas vezes, relacionada a um erro (valor) na previsão; para `classificadores`, essa medida tende a estar ligada a um tipo de `acurácia`, no sentido da _razão acertos e tentativas_.\n",
    "\n",
    "O split em treino e teste pode ser realizado com facilidade por meio da função `train_test_split` da biblioteca `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4231be68",
   "metadata": {},
   "source": [
    "Para começar devemos definir quantos dados serão utilizados para `teste` e quantos ficaram para `treino`. Percentualmente isso tende a variar entre _10 e 30%_. Dado que após todo o processamento ainda existem 333 exemplos, é razoável aplicar 25% do `dataset` para _teste_, dado que ainda assim exixtirão 249 _exemplos_ para _treinar_ o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02e9772a",
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout = 0.25\n",
    "seed = 1141"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7da00e",
   "metadata": {},
   "source": [
    "Note que os `Dataframes` de `features` e `target` foram criados anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c40c6800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O número TOTAL de dados é 333\n",
      "O número de dados para treino é 249\n",
      "O número de dados para teste é de 84\n"
     ]
    }
   ],
   "source": [
    "indices = df_tratado.index\n",
    "\n",
    "# faz o Holdout\n",
    "indices_treino, indices_teste = train_test_split(\n",
    "    indices, test_size=holdout, random_state=seed, stratify=df_target\n",
    ")\n",
    "\n",
    "# Separa em variáveis de treino e variáveis de teste\n",
    "# Features\n",
    "FEATURES_TREINO = df_features.loc[indices_treino]\n",
    "FEATURES_TESTE = df_features.loc[indices_teste]\n",
    "\n",
    "# Target\n",
    "TARGET_TREINO = df_target.loc[indices_treino]\n",
    "TARGET_TESTE = df_target.loc[indices_teste]\n",
    "\n",
    "print(f'O número TOTAL de dados é {len(indices)}')\n",
    "print(f'O número de dados para treino é {len(FEATURES_TREINO)}')\n",
    "print(f'O número de dados para teste é de {len(FEATURES_TESTE)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f636edc4",
   "metadata": {},
   "source": [
    "## Exportando os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded7b1aa",
   "metadata": {},
   "source": [
    "Os `modelos` que serão treinados terão seu `algoritmos` em _arquivo diferente_, mas precisam ter acesso aos dados tratados neste `notebook`. Para isso, os `Dataframes` gerados após o pré-processamento serão `exportados` como _arquivos CSV_ para que possam ser `importados` nos outros `notebooks`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01b3d88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_TREINO.to_csv('Features para treino.csv')\n",
    "FEATURES_TESTE.to_csv('Features para teste.csv')\n",
    "TARGET_TREINO.to_csv('Target para treino.csv')\n",
    "TARGET_TESTE.to_csv('Target para teste.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66aa5f96",
   "metadata": {},
   "source": [
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb87331",
   "metadata": {},
   "source": [
    "1. Artigo relacionado ao `Dataset`, disponívle em: "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ilumpy",
   "language": "python",
   "name": "quest4_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
